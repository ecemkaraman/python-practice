{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd0eb5a",
   "metadata": {},
   "source": [
    "# Mastering the Pandas Library\n",
    "This notebook covers detailed topics related to the Pandas library in Python, following a structured outline for practical use cases and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1387a7f2",
   "metadata": {},
   "source": [
    "## 1. Basics and Fundamentals\n",
    "- Series: 1D & homogeneous → container for scalars - aka a column\n",
    "    - If you create a Series from a dict, the keys will then become the labels. \n",
    "- DataFrame: 2D & heterogeneous → contains a collection of *series*\n",
    "    - Both can be created from dictionaries, lists, NumPy arrays, or external files.\n",
    "    - With the `index` argument, you can name your own indexes for Series or row titles for DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163a045b-a3ae-4c9f-8f84-5b898505ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a Series\n",
    "series = pd.Series([10, 20, 30], name='Sample Series')\n",
    "print(series)\n",
    "\n",
    "# Create a Series with custom labelled index\n",
    "data = [10, 20, 30, 40]\n",
    "labelled_series = pd.Series(data, index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "print(labelled_series)\n",
    "\n",
    "# Creating a DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Inspecting a DataFrame\n",
    "print(f\"# First 5 rows:\\n{df.head()}\\n\") # tail()=last x rows\n",
    "print(\"\\nQuick One-shot Summary\")\n",
    "df.info() #directly outputs to console, can't do print(df.info())\n",
    "print(f\"# Summary of numerical columns(mean, count, std, min, max):\\n{df.describe()}\\n\")\n",
    "print(f\"# (row count, column count): {df.shape}\\n\")\n",
    "print(f\"# Column Data types:\\n{df.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f79e51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Data I/O: Read/Write Files of Various Formats\n",
    "**CSV**: `pd.read_csv()`, `DataFrame.to_csv()`\n",
    " - `index=False` tells Pandas **not to include the row index** in the exported file. By default, the DF row index is the 1st column in the output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('input.csv', index=False) #write\n",
    "csv_data = pd.read_csv('output.csv') #read\n",
    "print(csv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907d663",
   "metadata": {},
   "source": [
    "**JSON**: `pd.read_json()` / `.to_json()`\n",
    "- **`orient`**: Specifies the JSON format to control how data is structured during conversion between DF/Series and JSON. Possible values:\n",
    "    - **`records`**: For row-based processing or compatibility with APIs.\n",
    "    - **`columns`**: Default; useful for column-wise data storage.\n",
    "    - **`index`**: For row-wise lookup based on indices.\n",
    "    - **`split`**: Ideal for recreating DataFrame structure programmatically.\n",
    "    - **`table`**: For interoperability with table-oriented frameworks or tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0edab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and writing JSON files\n",
    "df.to_json('example.json', orient='records')\n",
    "json_data = pd.read_json('example.json')\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ecbbbd",
   "metadata": {},
   "source": [
    "**Excel**: `pd.read_excel()`, `DataFrame.to_excel()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5426e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('example.xlsx', sheet_name='Sheet1')\n",
    "df.to_excel('output.xlsx', sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6bdd73",
   "metadata": {},
   "source": [
    "**SQL**: `pd.read_sql()` / `.to_sql()` \n",
    "\n",
    "- **`pd.read_sql`**: Reads data into a DF from either an **entire table or a SQL query**, offering flexibility.\n",
    "- **`pd.read_sql_query`**: **Executes SQL queries** and loads the result into a DF. **Only accepts SQL queries** as input.\n",
    "- **SQL Connection**:A DB connection (e.g., using `sqlalchemy.create_engine`) is required for both reading and writing.\n",
    "     - `con=engine`=DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///:memory:') #Connect to DB\n",
    "# read_sql()\n",
    "df = pd.read_sql('SELECT * FROM table_name', con=engine) #Read via query\n",
    "df = pd.read_sql('table_name', con=engine)  # Reads entire table\n",
    "\n",
    "# read_sql_query()\n",
    "df = pd.read_sql_query('SELECT * FROM table_name', con=engine)\n",
    "\n",
    "# Write to SQL DB\n",
    "df.to_sql('output_table', engine)\n",
    "df.to_sql('output_table', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16aec78",
   "metadata": {},
   "source": [
    "**Parquet**: `pd.read_parquet()` / `.to_parquet()`\n",
    "- **Parquet** is a **columnar storage file format** that is optimized for efficient data storage and retrieval, commonly used in big data processing frameworks like Apache Spark, Hadoop, and Pandas. It is designed to handle large datasets efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('example.parquet')\n",
    "df.to_parquet('example.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec18c9",
   "metadata": {},
   "source": [
    "**Handling Large Files**:Chunk-based reading (`chunksize`)->Specifies the number of rows to read at a time. \n",
    "- UC: File types with tabular data and are processed row-by-row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"large_dataset.csv\", \"w\") as f:\n",
    "    f.write(csv_data)\n",
    "\n",
    "# Read the CSV file in chunks\n",
    "chunk_size = 2  # Number of rows per chunk\n",
    "chunk_iterator = pd.read_csv(\"large_dataset.csv\", chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk\n",
    "for chunk in chunk_iterator:\n",
    "    print(f\"Processing chunk:\\n{chunk}\\n\")\n",
    "    # Example: Perform operations like filtering\n",
    "    filtered_chunk = chunk[chunk['Age'] > 30]\n",
    "    print(f\"Filtered chunk:\\n{filtered_chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee9e3f7",
   "metadata": {},
   "source": [
    "## 3. Indexing and Selection\n",
    "Access, subset and filter large datasets for specific rows/columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef13dd-6e1e-4bfb-a165-a0e6b80e6451",
   "metadata": {},
   "source": [
    "#### **`loc` vs `iloc`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e0380-9cff-4001-acea-a526ab980c40",
   "metadata": {},
   "source": [
    "- **`loc`:** Label-based indexing-> Access rows/columns using **labels** \n",
    "  - Syntax: `df.loc[row_labels, column_labels]`.\n",
    "- **`iloc`:** Position-based indexing-> Access rows/columns using **integer positions** \n",
    "  - Syntax: `df.iloc[row_positions, column_positions]`.\n",
    "Both **`loc`** and **`iloc`** apply to **rows and columns**.\n",
    "- To get rows only, use the 1st argument: `df.loc/iloc[rows, :]` →you can omit the :\n",
    "- To get columns only, use the 2nd argument: `df.loc/iloc[:, columns]`\n",
    "- To get both row & columns, specify both arguments: `df.loc/iloc[rows, columns]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c7faa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name  Age      City  Bank Balance\n",
      "row1    Alice   25  New York           -10\n",
      "row2      Bob   30    London           100\n",
      "row3  Charlie   35     Paris            50\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'London', 'Paris'],\n",
    "    'Bank Balance': [-10, 100, 50]\n",
    "}, index=['row1', 'row2', 'row3'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fb77d",
   "metadata": {},
   "source": [
    "#### 1. **Column Selection**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d95063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column-Based Indexing\n",
    "print(\"Single column (by label):\\n\", df['Name'])  \n",
    "print(\"Multiple columns:\\n\", df[['Name', 'City']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92216f6-599d-47b0-9c57-5f17d19f30a5",
   "metadata": {},
   "source": [
    "- Single column: `df['column_name']`\n",
    "- Multiple columns: `df[['col1', 'col2']]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5dd1d-8076-44c8-8ced-3cb6a6732d41",
   "metadata": {},
   "source": [
    "#### 2. **Row Selection**: Return specified row(s) as a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6480b71-b0fa-4507-bfd1-67e9df8f37cc",
   "metadata": {},
   "source": [
    "- By label: `df.loc['row_label']`\n",
    "- By position(int): `df.iloc[row_index]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row-Based Indexing with `iloc`\n",
    "print(\"\\nSingle row (by position):\\n\", df.iloc[0])  \n",
    "print(\"Multiple rows:\\n\", df.iloc[[0, 2]])  \n",
    "print(\"Specific value (by position):\", df.iloc[1, 2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51239636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row-Based Indexing with `loc`\n",
    "print(\"\\nSingle row (by label):\\n\", df.loc['row1'])  \n",
    "print(\"Multiple rows:\\n\", df.loc[['row1', 'row3']])  \n",
    "print(\"Specific value (by label):\", df.loc['row2', 'City']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f7d7b-e0a7-495a-8f40-fac612d08e67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. **Select a Specific Cell: Row&Column**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8702c78-06fc-4d2f-8a8e-ee60e3037b0e",
   "metadata": {},
   "source": [
    "- By label: `df.loc['row_label', 'column_name']`\n",
    "- By position: `df.iloc[row_index, col_index]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a95403",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_by_label = df.loc['row2', 'City']  \n",
    "print(\"Cell by label:\", cell_by_label)\n",
    "\n",
    "cell_by_position = df.iloc[1, 2] \n",
    "print(\"Cell by position:\", cell_by_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ddeb19",
   "metadata": {},
   "source": [
    "#### 4. **Slicing**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f6b37-b960-464a-b632-d644fe67dcad",
   "metadata": {},
   "source": [
    "- Rows: `df[2:5]` \n",
    "- Rows/columns by labels(inclusive): `df.loc[start_label:end_label]`\n",
    "- Rows/columns by indices(exclusive): `df.iloc[start:end]` \n",
    "- **Label slicing includes the end label, index slicing excludes the end index!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a843ef70-fce9-413b-97f8-d1002af1797b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d019992-38f3-412f-a2d7-969ffe1b4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_slice = df[1:3]  # Slicing by row indices - exclusive \n",
    "print(\"Slicing rows (df[1:3]):\\n\", row_slice)\n",
    "\n",
    "# Slicing Rows/Columns by Labels - inclusive\n",
    "label_slice = df.loc['row1':'row2', 'Name':'Age']  \n",
    "print(\"\\nSlicing by labels:\\n\", label_slice)\n",
    "\n",
    "# Slicing Rows/Columns by Indices\n",
    "index_slice = df.iloc[0:2, 0:2]  \n",
    "print(\"\\nSlicing by indices:\\n\", index_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2bcf1-8d31-40d5-9cb5-c4481d03556c",
   "metadata": {},
   "source": [
    "#### 5.Conditional Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d32a6-ce1d-44d3-846c-4777cff7d52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c47020-bab9-47d9-b874-04d54d72cc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b113c29-2228-4fe3-9e0e-a000de1ebd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B  C  D  E\n",
      "0  10   5  2  1  0\n",
      "1  20  15  4  3 -1\n",
      "2  30  25  6  5 -2\n",
      "3  40  35  8  7 -3\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'A': [10, 20, 30, 40],\n",
    "    'B': [5, 15, 25, 35],\n",
    "    'C': [2, 4, 6, 8],\n",
    "    'D': [1, 3, 5, 7],\n",
    "    'E': [0, -1, -2, -3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7544dc8f-e2f2-4919-8599-65ab687379f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C     D      E\n",
       "0  True  True  True  True  False\n",
       "1  True  True  True  True  False\n",
       "2  True  True  True  True  False\n",
       "3  True  True  True  True  False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df > 0 \n",
    "#Returns a DF of boolean values, indicating where each element satisfies the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1b866-80e8-4a0e-8a39-bef5381d3741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bb80121-64fd-4184-93c7-c71e7616510e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B  C  D   E\n",
       "0  10   5  2  1 NaN\n",
       "1  20  15  4  3 NaN\n",
       "2  30  25  6  5 NaN\n",
       "3  40  35  8  7 NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df > 0]\n",
    "#Returns a DF with values replaced by NaN if False, keep original values if True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cbc2f3-aa7f-4aee-9924-78c191c085f9",
   "metadata": {},
   "source": [
    "- **Filter rows**: `df[df['column_name'] > value]`\n",
    "    - Use **`df[...]`** for basic filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94f90a38-9ee5-4c90-9ada-9054225f34e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B  C  D  E\n",
       "2  30  25  6  5 -2\n",
       "3  40  35  8  7 -3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic row filtering: `df[df['column_name'] > value]`\n",
    "df[df['C'] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69f5a178-1a24-42f5-9a61-0200e668d03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A  C\n",
       "1  20  4\n",
       "2  30  6\n",
       "3  40  8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use `df.loc[df['column_name'] == 'value', [col1, col2]` for row filtering + select specific columns\n",
    "df.loc[df['C'] > 3, ['A', 'C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd61225-dc76-453c-a0a4-619c2924aaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8af0cc-f71c-4177-ab1e-c245a31427be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320af526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple conditions: Use bitwise operators (&, |, ~) with parentheses \n",
    "print(df[(df['Age'] > 25) & (df[\"Name\"] == 'Charlie')]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7135bebe",
   "metadata": {},
   "source": [
    "6. **Advanced Indexing**:\n",
    "    - Select specific rows and columns: `df.loc[[row1, row2], [col1, col2]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a19c67",
   "metadata": {},
   "source": [
    "**Setting and Resetting Index**:\n",
    " - `.set_index()`: Create a MultiIndex for hierarchical organization.\n",
    " - `.reset_index()`: Flatten the index back into regular columns.\n",
    " \n",
    " Set MultiIndex: set_index() creates MultiIndex \n",
    "Reset MultiIndex: reset_index() flattens the index back into regular columns.\n",
    "- **Single-Level vs Multi-Level Data**: Single-level data uses a flat index for rows/columns, while multi-level (or hierarchical) data uses multiple index levels to represent relationships or groupings within the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8986fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting and resetting an index\n",
    "df.set_index('Name', inplace=True)\n",
    "print(df)\n",
    "df.reset_index(inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed163ac8-8995-444d-a652-f82db8b0f37f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **MultiIndex (hierarchical indexing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5631710-5ffb-4c67-b959-bf39ec1b46f2",
   "metadata": {},
   "source": [
    "- **MultiIndex** is a hierarchical index structure->manage multi-D data by using multiple levels of row or column indices.\n",
    "- **How to Create**: \n",
    "    - `set_index()` is the most common way to create a MultiIndex by promoting one or more columns to row indices.\n",
    "    - Alternative: `pd.MultiIndex.from_tuples()`/`.from_product()`->more flexible\n",
    "\n",
    "- `reset_index()` is used to revert the MultiIndex into columns.\n",
    "\n",
    "- **Why Use It**: It organizes and analyzes grouped or hierarchical datasets more efficiently, enabling operations like slicing, aggregation, and pivoting on multiple levels.\n",
    "Use `pd.MultiIndex.from_tuples()` or `set_index()` to define multiple index levels, enabling hierarchical access and manipulation of data.\n",
    "- **`pd.IndexSlice`** is better for slicing when working with **MultiIndex** because it provides a clean and flexible way to specify slices across multiple levels of the index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc9ede-52e7-4f57-8730-a3c35a6708da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9574708-c866-4396-bc48-c0c0009fc536",
   "metadata": {},
   "source": [
    "Clean raw data by filling missing values, converting types, and removing duplicates.\n",
    "- **Handling Missing Data**:\n",
    "    - `.isna()`\n",
    "    - `.fillna()`\n",
    "    - `.dropna()`\n",
    "    - `.interpolate()`: Fills missing values by estimating them using neighboring values.\n",
    "- For nun-numeric data, it's ok to use **`None`** for missing values, but BP to use **`np.nan`** for numerical or mixed datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f175f6e-1d42-42a0-bc1b-15e08f6fe0d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b47d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [1, np.nan, 3], 'B': [4, 5, np.nan]})\n",
    "print(df)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isna())\n",
    "print(\"Total Number of Missing Values:\\n\", df.isna().sum())\n",
    "\n",
    "# Fill missing values\n",
    "df_filled = df.fillna(0)\n",
    "print(\"\\nAfter filling missing values with 0:\\n\", df_filled)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nAfter dropping rows with missing values:\\n\", df_dropped)\n",
    "\n",
    "# Interpolate missing values\n",
    "df_interpolated = df.interpolate()\n",
    "print(\"\\nAfter interpolating missing values:\\n\", df_interpolated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c0081f",
   "metadata": {},
   "source": [
    "- **Data Type Conversion**: `.astype()`\n",
    "- **String Operations**:`.str` methods for cleaning and manipulating text data. (.upper(), .strip(), .replace(), .contains(), .len())\n",
    "- **Duplicated Data**:\n",
    "    - **`.duplicated()`**: Flags duplicate rows.\n",
    "    - **`.drop_duplicates()`**: Removes duplicates, keeping the first occurrence by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba77b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob'],\n",
    "    'Age': [25, 30, 25, 35, 30]\n",
    "})\n",
    "\n",
    "# Converting data types\n",
    "df['Age'] = df['Age'].astype(float)\n",
    "print(df.dtypes)\n",
    "\n",
    "# String operations\n",
    "df['Name'] = df['Name'].str.upper()\n",
    "print(df)\n",
    "\n",
    "# Check for duplicated rows\n",
    "duplicates = df.duplicated()\n",
    "print(\"Duplicated rows:\\n\", duplicates)\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(\"\\nDataFrame after dropping duplicates:\\n\", df_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f652e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Data Transformation\n",
    "Transform datasets into desired shapes or formats for analysis.\n",
    "- **Column Operations**:\n",
    "    - Add, remove, rename, and reorder columns.\n",
    "- **Apply and Map Functions**:\n",
    "    - `.apply()`, `.map()`, `.applymap()` for custom transformations.\n",
    "- **Sorting**:\n",
    "    - `.sort_values()` / `.sort_index()`.\n",
    "- **Pivot Tables**:\n",
    "    - `.pivot_table()` for aggregations and summaries.\n",
    "- **Melt and Reshape**:\n",
    "    - `.melt()`, `.stack()`, `.unstack()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'London', 'Paris']\n",
    "}, index=['row1', 'row2', 'row3'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Salary'] = [50000, 60000, 70000] \n",
    "print(\"Added a Salary column:\\n\", df)\n",
    "\n",
    "df['Salary'] = df['Salary'] * 1.1\n",
    "print(\"\\nIncrease Salary by 10%:\\n\", df)\n",
    "\n",
    "df.rename(columns={'Salary': 'Income'}, inplace=True) \n",
    "print(\"\\nRenamed Salary column to Income:\\n\", df)\n",
    "\n",
    "df['Net_income'] = df['Income'].apply(lambda x: x * 0.7)\n",
    "print(\"\\n Create Net_income column, applied a lambda function:\\n\", df)\n",
    "\n",
    "pivot = pd.pivot_table(df, values='Income', index='Age', aggfunc='mean')\n",
    "print(\"\\nPivot table (Mean income by Age):\\n\", pivot)\n",
    "\n",
    "df = df.drop(columns=['Income'])\n",
    "print(\"\\nDeleted Income column:\\n\", df)\n",
    "\n",
    "df['Net_income'].replace(38500.0, 40000.0, inplace=True)  # Replace \n",
    "print(\"\\nReplace Alice's Net Income:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4c81b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Aggregation and Grouping\n",
    "**GroupBy Operations**: Group data by a column and calculate aggregate statistics.\n",
    " - `.groupby()` for aggregation (`sum`, `mean`, `count`, etc.).\n",
    " - **`.groupby('Col1', 'Col2').agg()`** applies multiple aggregation functions (sum, mean, min, max) on different columns (Col1, Col2) in a single operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Category': ['A', 'A', 'B', 'B', 'A', 'B'],\n",
    "    'Value1': [10, 20, 30, 40, 50, 60],\n",
    "    'Value2': [5, 15, 25, 35, 45, 55]\n",
    "})\n",
    "print(df)\n",
    "\n",
    "# Group by 'Category' and calculate sum of each column\n",
    "grouped_sum = df.groupby('Category').sum()\n",
    "print(\"GroupBy Sum:\\n\", grouped_sum)\n",
    "\n",
    "# Group by 'Category' and count non-null entries in each column\n",
    "grouped_count = df.groupby('Category').count()\n",
    "print(\"\\nGroupBy Count:\\n\", grouped_count)\n",
    "\n",
    "# Group by 'Category' and calculate multiple aggregation statistics\n",
    "grouped = df.groupby('Category').agg({\n",
    "    'Value1': ['sum', 'mean'],    # Sum and mean of Value1\n",
    "    'Value2': ['min', 'max']      # Min and max of Value2\n",
    "})\n",
    "print(\"GroupBy Aggregation using .agg():\\n\", grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3191855",
   "metadata": {},
   "source": [
    "**Window and Rolling Operations**: Apply rolling metrics on time-series data \n",
    "- **`set_index()`**: Sets the specified column as the index of the DF\n",
    "- **`rolling(window=3)`**: Creates a rolling window view of the data over a specified window size-> can calculate metrics like `mean()`, `min()`, `max()`,  `std()`,  `var()`,  `sum()` within that window. Can also use `count()`and `apply()` (for custom functions).\n",
    "- **`expanding()`**: Expands the window to include all prior data points for each row, allowing for cumulative calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Date': pd.date_range('2023-01-01', periods=6, freq='D'),\n",
    "    'Value': [10, 20, 30, 40, 50, 60]\n",
    "})\n",
    "print(df)\n",
    "\n",
    "# Set Date as index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Apply rolling window operation (e.g., 3-day rolling sum)\n",
    "df['Rolling_Sum'] = df['Value'].rolling(window=3).sum()\n",
    "\n",
    "# Apply expanding window operation (cumulative sum)\n",
    "df['Expanding_Sum'] = df['Value'].expanding().sum()\n",
    "\n",
    "print(\"\\nRolling and Expanding Operations:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bbf20c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. Merging and Combining Data\n",
    "Combine data from multiple sources into a single coherent dataset.\n",
    "- **Merge and Join**:\n",
    "    - `.merge()` (similar to SQL joins).\n",
    "    - `.join()` for index-based merging.\n",
    "- **Concatenation**:\n",
    "    - `pd.concat()` to combine along a specific axis.\n",
    "- **Database-like Operations**:\n",
    "    - Append, union, intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two DataFrames\n",
    "df1 = pd.DataFrame({'ID': [1, 2], 'Name': ['Alice', 'Bob']})\n",
    "df2 = pd.DataFrame({'ID': [2, 3], 'City': ['London', 'Paris']})\n",
    "\n",
    "# Merge DataFrames\n",
    "merged = pd.merge(df1, df2, on='ID', how='outer')\n",
    "print(merged)\n",
    "\n",
    "\n",
    "# Concatenating DataFrames\n",
    "df3 = pd.DataFrame({'Name': ['Eve'], 'Age': [40], 'Income': [80000]})\n",
    "concat = pd.concat([df, df3], ignore_index=True)\n",
    "print(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e3738",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 8. Time-Series Data\n",
    "Handle and analyze temporal data efficiently.\n",
    "- **Datetime Handling**:\n",
    "    - `pd.to_datetime()`, `.dt` accessor for datetime attributes.\n",
    "- **Resampling**:\n",
    "    - `.resample()` for up/down sampling of time-series data.\n",
    "- **Shifting and Lagging**:\n",
    "    - `.shift()` for lag analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a time-series DataFrame\n",
    "time_data = pd.date_range(start='2023-01-01', periods=5, freq='D')\n",
    "time_df = pd.DataFrame({'Date': time_data, 'Value': range(5)})\n",
    "time_df.set_index('Date', inplace=True)\n",
    "print(time_df)\n",
    "\n",
    "# Resampling data\n",
    "resampled = time_df.resample('2D').sum()\n",
    "print(resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d6045d",
   "metadata": {},
   "source": [
    "## 9. Performance Optimization\n",
    "Optimize memory and computational performance.\n",
    "- **Memory Optimization**:\n",
    "    - Reducing data size by converting types (`pd.to_numeric()` with `downcast`).\n",
    "- **Vectorization**:\n",
    "    - Leveraging NumPy-backed operations over Python loops.\n",
    "- **Efficient I/O**:\n",
    "    - Use binary formats like Parquet or Feather for faster reads/writes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing memory usage by converting data types\n",
    "optimized_df = df.copy()\n",
    "optimized_df['Income'] = pd.to_numeric(optimized_df['Income'], downcast='integer')\n",
    "print(optimized_df.dtypes)\n",
    "\n",
    "# Using vectorized operations\n",
    "df['Adjusted_Income'] = df['Income'] * 0.9\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9aafd0",
   "metadata": {},
   "source": [
    "## 10. Visualization\n",
    "Quickly visualize data trends and distributions.\n",
    "- **Basic Plotting**:\n",
    "    - `.plot()` for quick visualizations.\n",
    "- **Integration with Libraries**:\n",
    "    - Seamless use with `matplotlib`, `seaborn`, and `plotly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3771d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic plotting\n",
    "df['Income'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578d30e",
   "metadata": {},
   "source": [
    "## 11. Advanced Topics\n",
    "Master advanced operations like MultiIndex, sparse matrices, custom aggregations, and handling hierarchical data.\n",
    "- **Custom Aggregations**:\n",
    "    - Using `.agg()` with lambda functions or multiple aggregations per column.\n",
    "- **MultiIndex Operations**:\n",
    "    - Slicing, swapping levels, and combining MultiIndex DataFrames.\n",
    "- **Categorical Data**:\n",
    "    - Optimizing memory and performance with `.astype('category')`.\n",
    "- **Sparse Data**:\n",
    "    - Handling sparse DataFrames for memory efficiency.\n",
    "- **Working with JSON/Hierarchical Data**:\n",
    "    - Normalizing nested JSON with `pd.json_normalize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiIndex DataFrame\n",
    "multi_index_df = pd.DataFrame({'Category': ['A', 'A', 'B'], 'Subcategory': ['X', 'Y', 'Z'], 'Values': [1, 2, 3]})\n",
    "multi_index_df.set_index(['Category', 'Subcategory'], inplace=True)\n",
    "print(multi_index_df)\n",
    "\n",
    "# Custom aggregations\n",
    "custom_agg = df.agg({'Income': ['sum', 'mean'], 'Age': 'max'})\n",
    "print(custom_agg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
